"""
æ–‡ä»¶æ£€ç´¢æœåŠ¡
ä½¿ç”¨æ··åˆæ£€ç´¢ï¼ˆBM25 + å‘é‡ç›¸ä¼¼åº¦ï¼‰æŸ¥æ‰¾æœ€ç›¸å…³çš„Excelæ–‡ä»¶
"""
from typing import List
from backend.utils.es_client import es_client
from backend.utils.openai_client import openai_client
from backend.models.schemas import FileSearchResult, ColumnInfo


class FileRetriever:
    """æ–‡ä»¶æ£€ç´¢å™¨"""
    
    def __init__(self):
        # ç®€å•çš„å†…å­˜ç¼“å­˜
        self._embedding_cache = {}
        self._search_cache = {}
    
    async def search_files(self, question: str, top_k: int = 3) -> List[FileSearchResult]:
        """
        æ£€ç´¢ç›¸å…³æ–‡ä»¶
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            top_k: è¿”å›top-kä¸ªç»“æœ
            
        Returns:
            æ£€ç´¢ç»“æœåˆ—è¡¨
        """
        import time
        start_time = time.time()
        
        # 1. ç”Ÿæˆé—®é¢˜çš„embeddingå‘é‡ï¼ˆå¸¦ç¼“å­˜å’Œè¶…æ—¶ï¼‰
        try:
            import asyncio
            import hashlib
            
            # æ£€æŸ¥ç¼“å­˜
            question_hash = hashlib.md5(question.encode()).hexdigest()
            if question_hash in self._embedding_cache:
                question_embedding = self._embedding_cache[question_hash]
                print(f"ğŸ“Š ä½¿ç”¨ç¼“å­˜çš„Embedding")
            else:
                question_embedding = await asyncio.wait_for(
                    openai_client.generate_embedding(question),
                    timeout=5.0  # 5ç§’è¶…æ—¶
                )
                # ç¼“å­˜ç»“æœ
                self._embedding_cache[question_hash] = question_embedding
                print(f"ğŸ“Š ç”Ÿæˆæ–°Embeddingå¹¶ç¼“å­˜")
            
            embedding_time = time.time() - start_time
            print(f"ğŸ“Š Embeddingå¤„ç†æ—¶é—´: {embedding_time:.4f}ç§’")
        except asyncio.TimeoutError:
            print("âš ï¸ Embeddingç”Ÿæˆè¶…æ—¶ï¼Œä½¿ç”¨ç®€åŒ–æ£€ç´¢")
            # ä½¿ç”¨ç®€åŒ–æ£€ç´¢ä½œä¸ºå¤‡é€‰
            return await self._fallback_search(question, top_k)
        
        # 2. æ„å»ºæ··åˆæ£€ç´¢æŸ¥è¯¢
        query = self._build_hybrid_query(question, question_embedding)
        
        # 3. æ‰§è¡Œæœç´¢ï¼ˆå¸¦è¶…æ—¶ï¼‰
        try:
            results = await asyncio.wait_for(
                es_client.search(query, size=top_k),
                timeout=3.0  # 3ç§’è¶…æ—¶
            )
            search_time = time.time() - start_time - embedding_time
            print(f"ğŸ“Š ESæœç´¢æ—¶é—´: {search_time:.4f}ç§’")
        except asyncio.TimeoutError:
            print("âš ï¸ ESæœç´¢è¶…æ—¶ï¼Œä½¿ç”¨ç®€åŒ–æ£€ç´¢")
            return await self._fallback_search(question, top_k)
        
        # 4. è½¬æ¢ä¸ºFileSearchResult
        search_results = []
        for hit in results:
            source = hit["_source"]
            
            # è½¬æ¢åˆ—ä¿¡æ¯
            columns = [
                ColumnInfo(**col) for col in source.get("columns", [])
            ]
            
            result = FileSearchResult(
                file_id=source["file_id"],
                file_name=source["file_name"],
                summary=source.get("summary", ""),
                score=hit["_score"],
                columns=columns
            )
            search_results.append(result)
        
        return search_results
    
    async def _fallback_search(self, question: str, top_k: int) -> List[FileSearchResult]:
        """
        å¤‡é€‰æ£€ç´¢æ–¹æ³•ï¼ˆå½“ä¸»è¦æ£€ç´¢è¶…æ—¶æ—¶ä½¿ç”¨ï¼‰
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            top_k: è¿”å›top-kä¸ªç»“æœ
            
        Returns:
            æ£€ç´¢ç»“æœåˆ—è¡¨
        """
        try:
            # ä½¿ç”¨ç®€å•çš„å…³é”®è¯æœç´¢
            simple_query = {
                "query": {
                    "multi_match": {
                        "query": question,
                        "fields": ["file_name^2", "summary", "columns.name", "columns.description"],
                        "type": "best_fields",
                        "fuzziness": "AUTO"
                    }
                },
                "size": top_k
            }
            
            results = await es_client.search(simple_query, size=top_k)
            
            # è½¬æ¢ä¸ºFileSearchResult
            search_results = []
            for hit in results:
                source = hit["_source"]
                
                # è½¬æ¢åˆ—ä¿¡æ¯
                columns = [
                    ColumnInfo(**col) for col in source.get("columns", [])
                ]
                
                result = FileSearchResult(
                    file_id=source["file_id"],
                    file_name=source["file_name"],
                    summary=source.get("summary", ""),
                    score=hit["_score"],
                    columns=columns
                )
                search_results.append(result)
            
            print(f"ğŸ“Š ä½¿ç”¨å¤‡é€‰æ£€ç´¢ï¼Œæ‰¾åˆ° {len(search_results)} ä¸ªç»“æœ")
            return search_results
            
        except Exception as e:
            print(f"âŒ å¤‡é€‰æ£€ç´¢å¤±è´¥: {e}")
            return []
    
    def _build_hybrid_query(self, question: str, embedding: List[float]) -> dict:
        """
        æ„å»ºæ··åˆæ£€ç´¢æŸ¥è¯¢
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            embedding: é—®é¢˜çš„å‘é‡è¡¨ç¤º
            
        Returns:
            ESæŸ¥è¯¢å­—å…¸
        """
        query = {
            "query": {
                "script_score": {
                    "query": {
                        "bool": {
                            "should": [
                                # å…³é”®è¯æ£€ç´¢ï¼ˆBM25ï¼‰
                                {
                                    "multi_match": {
                                        "query": question,
                                        "fields": [
                                            "file_name^3",
                                            "summary^2",
                                            "columns.name^2",
                                            "columns.description^1"
                                        ],
                                        "type": "best_fields",
                                        "fuzziness": "AUTO"
                                    }
                                }
                            ]
                        }
                    },
                    "script": {
                        "source": """
                            double vectorScore = cosineSimilarity(params.query_vector, 'embedding') + 1.0;
                            double bm25Score = _score;
                            return vectorScore * 10 + bm25Score * 0.3;
                        """,
                        "params": {
                            "query_vector": embedding
                        }
                    }
                }
            }
        }
        
        return query


# å…¨å±€å®ä¾‹
file_retriever = FileRetriever()

