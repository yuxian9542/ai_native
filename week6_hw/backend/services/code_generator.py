"""
Pythonä»£ç ç”ŸæˆæœåŠ¡
æ ¹æ®ç”¨æˆ·é—®é¢˜å’Œæ–‡ä»¶å…ƒæ•°æ®ç”Ÿæˆå¯æ‰§è¡Œçš„åˆ†æä»£ç 
"""
import ast
import traceback
from typing import Dict, Any, Tuple, Optional
from backend.utils.openai_client import openai_client
from backend.models.schemas import FileSearchResult, CodeGenerationResult
from backend.utils.logger import logger


class CodeGenerator:
    """ä»£ç ç”Ÿæˆå™¨"""
    
    async def generate_code(
        self,
        question: str,
        file_info: FileSearchResult
    ) -> CodeGenerationResult:
        """
        ç”Ÿæˆåˆ†æä»£ç 
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            file_info: é€‰ä¸­çš„æ–‡ä»¶ä¿¡æ¯
            
        Returns:
            ä»£ç ç”Ÿæˆç»“æœ
        """
        # ç¬¬ä¸€æ­¥ï¼šæ•°æ®åˆ†æå’Œè§£é‡Š
        print("ğŸ” å¼€å§‹æ•°æ®åˆ†æ...")
        data_analysis = await self._analyze_data_requirements(question, file_info)
        print(f"ğŸ“Š æ•°æ®åˆ†æç»“æœ: {data_analysis}")
        
        # ç¬¬äºŒæ­¥ï¼šæ„å»ºåŒ…å«æ•°æ®åˆ†æçš„æç¤ºè¯
        prompt = self._build_prompt_with_analysis(question, file_info, data_analysis)
        
        messages = [
            {"role": "system", "content": self._get_system_prompt()},
            {"role": "user", "content": prompt}
        ]
        
        # è°ƒç”¨GPT-5ç”Ÿæˆä»£ç 
        response = await openai_client.chat_completion(
            messages,
            model="gpt-4.1",
            temperature=0.2,
            max_tokens=2000
        )
        
        # è§£æå“åº”
        try:
            result_json = openai_client.extract_json(response)
        except Exception as e:
            logger.log_error(
                "code_generation_json_parse_failed",
                file_info.file_id,
                f"JSONè§£æå¤±è´¥: {e}",
                raw_response=response[:500]  # åªè®°å½•å‰500å­—ç¬¦
            )
            print(f"JSONè§£æå¤±è´¥: {e}")
            print(f"åŸå§‹å“åº”: {response}")
            raise
        
        # è·å–ç”Ÿæˆçš„ä»£ç 
        generated_code = result_json.get("code", "")
        
        # ç¬¬ä¸‰æ­¥ï¼šè¯­æ³•æ£€æŸ¥å’Œä¿®å¤
        print("ğŸ”§ å¼€å§‹è¯­æ³•æ£€æŸ¥å’Œä¿®å¤...")
        fixed_code, fix_success, fix_error = await self.check_and_fix_syntax_errors(generated_code)
        
        if fix_success and fixed_code != generated_code:
            print("âœ… ä»£ç å·²è‡ªåŠ¨ä¿®å¤è¯­æ³•é”™è¯¯")
            logger.log_info(
                "code_syntax_fixed",
                file_info.file_id,
                "ä»£ç è¯­æ³•é”™è¯¯å·²è‡ªåŠ¨ä¿®å¤",
                original_code_length=len(generated_code),
                fixed_code_length=len(fixed_code)
            )
        elif not fix_success:
            print(f"âš ï¸ è¯­æ³•ä¿®å¤å¤±è´¥: {fix_error}")
            logger.log_error(
                "code_syntax_fix_failed",
                file_info.file_id,
                f"è¯­æ³•ä¿®å¤å¤±è´¥: {fix_error}"
            )
        
        code_result = CodeGenerationResult(
            code=fixed_code,  # ä½¿ç”¨ä¿®å¤åçš„ä»£ç 
            used_columns=result_json.get("used_columns", []),
            analysis_type=result_json.get("analysis_type", "æ•°æ®åˆ†æ"),
            expected_output=result_json.get("expected_output", ""),
            data_analysis=data_analysis  # æ·»åŠ æ•°æ®åˆ†æç»“æœ
        )
        
        return code_result

    async def _analyze_data_requirements(self, question: str, file_info: FileSearchResult) -> Dict[str, Any]:
        """
        åˆ†æç”¨æˆ·é—®é¢˜éœ€è¦ä»€ä¹ˆæ•°æ®å’Œå‡½æ•°
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            file_info: æ–‡ä»¶ä¿¡æ¯
            
        Returns:
            æ•°æ®åˆ†æç»“æœ
        """
        try:
            # æ„å»ºæ•°æ®åˆ†ææç¤ºè¯
            analysis_prompt = f"""
è¯·åˆ†æä»¥ä¸‹ç”¨æˆ·é—®é¢˜éœ€è¦ä»€ä¹ˆæ•°æ®å’Œå‡½æ•°ï¼š

ç”¨æˆ·é—®é¢˜: {question}

æ–‡ä»¶ä¿¡æ¯:
- æ–‡ä»¶å: {file_info.file_name}
- å·¥ä½œè¡¨: {file_info.sheet_name}
- åˆ—ä¿¡æ¯: {[col.name for col in file_info.columns] if file_info.columns else []}
- åˆ—è¯¦ç»†ä¿¡æ¯: {[f"{col.name} ({col.type}): {col.description}" for col in file_info.columns[:10]] if file_info.columns else []}
- æ•°æ®æ ·æœ¬: {file_info.metadata.get('sample_data', []) if file_info.metadata else []}

è¯·åˆ†æå¹¶è¿”å›JSONæ ¼å¼ç»“æœï¼š
{{
    "required_data": {{
        "tables": ["éœ€è¦å“ªäº›è¡¨"],
        "columns": ["éœ€è¦å“ªäº›åˆ—"],
        "data_types": ["æ•°æ®ç±»å‹åˆ†æ"]
    }},
    "required_functions": ["sum", "avg", "count", "max", "min", "groupby", "filter", "sort"],
    "data_values": {{
        "column_name": ["å…·ä½“æ•°å€¼åˆ—è¡¨"],
        "column_name2": ["å…·ä½“æ•°å€¼åˆ—è¡¨"]
    }},
    "analysis_explanation": "è¯¦ç»†è§£é‡Šéœ€è¦ä»€ä¹ˆæ•°æ®ï¼Œä¸ºä»€ä¹ˆéœ€è¦è¿™äº›æ•°æ®ï¼Œå¦‚ä½•ä½¿ç”¨è¿™äº›æ•°æ®"
}}

æ³¨æ„ï¼š
1. æ ¹æ®ç”¨æˆ·é—®é¢˜ç¡®å®šéœ€è¦å“ªäº›åˆ—çš„æ•°æ®
2. ç¡®å®šéœ€è¦ä»€ä¹ˆç»Ÿè®¡å‡½æ•°ï¼ˆsumã€avgã€countç­‰ï¼‰
3. æ˜¾ç¤ºå…·ä½“çš„æ•°æ®æ•°å€¼
4. è§£é‡Šä¸ºä»€ä¹ˆéœ€è¦è¿™äº›æ•°æ®
"""
            
            # è°ƒç”¨GPT-4è¿›è¡Œæ•°æ®åˆ†æ
            response = await openai_client.chat_completion(
                [{"role": "user", "content": analysis_prompt}],
                model="gpt-4",
                temperature=0.1,
                max_tokens=1500
            )
            
            # è§£æJSONå“åº”
            result = openai_client.extract_json(response)
            
            print(f"ğŸ“Š æ•°æ®åˆ†æå®Œæˆ:")
            print(f"  - éœ€è¦çš„æ•°æ®: {result.get('required_data', {})}")
            print(f"  - éœ€è¦çš„å‡½æ•°: {result.get('required_functions', [])}")
            print(f"  - æ•°æ®è§£é‡Š: {result.get('analysis_explanation', '')}")
            
            return result
            
        except Exception as e:
            print(f"âŒ æ•°æ®åˆ†æå¤±è´¥: {e}")
            # è¿”å›é»˜è®¤åˆ†æç»“æœ
            return {
                "required_data": {
                    "tables": [file_info.sheet_name or "æœªçŸ¥è¡¨"],
                    "columns": [col.name for col in file_info.columns] if file_info.columns else [],
                    "data_types": [col.type for col in file_info.columns] if file_info.columns else ["æœªçŸ¥ç±»å‹"]
                },
                "required_functions": ["sum", "avg"],
                "data_values": {},
                "analysis_explanation": f"åŸºäºç”¨æˆ·é—®é¢˜'{question}'ï¼Œéœ€è¦åˆ†ææ–‡ä»¶'{file_info.file_name}'çš„æ•°æ®"
            }

    def _build_prompt_with_analysis(self, question: str, file_info: FileSearchResult, data_analysis: Dict[str, Any]) -> str:
        """
        æ„å»ºåŒ…å«æ•°æ®åˆ†æçš„æç¤ºè¯
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            file_info: æ–‡ä»¶ä¿¡æ¯
            data_analysis: æ•°æ®åˆ†æç»“æœ
            
        Returns:
            å®Œæ•´çš„æç¤ºè¯
        """
        # è·å–åŸºç¡€æ–‡ä»¶ä¿¡æ¯
        file_path = file_info.processed_file_path or "æœªçŸ¥æ–‡ä»¶è·¯å¾„"
        sheet_name = file_info.sheet_name or "Sheet1"
        
        # æ„å»ºæ•°æ®åˆ†æéƒ¨åˆ†
        analysis_section = f"""
## æ•°æ®åˆ†æç»“æœ
æ ¹æ®ç”¨æˆ·é—®é¢˜åˆ†æï¼Œéœ€è¦ä»¥ä¸‹æ•°æ®å’Œå‡½æ•°ï¼š

### éœ€è¦çš„æ•°æ®:
- è¡¨æ ¼: {', '.join(data_analysis.get('required_data', {}).get('tables', []))}
- åˆ—: {', '.join(data_analysis.get('required_data', {}).get('columns', []))}
- æ•°æ®ç±»å‹: {', '.join(data_analysis.get('required_data', {}).get('data_types', []))}

### éœ€è¦çš„å‡½æ•°:
{', '.join(data_analysis.get('required_functions', []))}

### å…·ä½“æ•°æ®æ•°å€¼:
"""
        
        # æ·»åŠ å…·ä½“æ•°æ®æ•°å€¼
        data_values = data_analysis.get('data_values', {})
        for column, values in data_values.items():
            if values:
                analysis_section += f"- {column}: {values[:10]}{'...' if len(values) > 10 else ''}\n"
        
        analysis_section += f"""
### åˆ†æè§£é‡Š:
{data_analysis.get('analysis_explanation', '')}

## ä»£ç ç”Ÿæˆè¦æ±‚
åŸºäºä»¥ä¸Šæ•°æ®åˆ†æï¼Œç”ŸæˆPythonä»£ç æ¥å›ç­”ç”¨æˆ·é—®é¢˜ã€‚
"""
        
        # æ„å»ºå®Œæ•´çš„æç¤ºè¯
        prompt = f"""
ç”¨æˆ·é—®é¢˜: {question}

æ–‡ä»¶ä¿¡æ¯:
- æ–‡ä»¶è·¯å¾„: {file_path}
- å·¥ä½œè¡¨: {sheet_name}
- åˆ—ä¿¡æ¯: {file_info.metadata.get('columns', []) if file_info.metadata else []}

{analysis_section}

è¯·ç”ŸæˆPythonä»£ç æ¥åˆ†ææ•°æ®å¹¶å›ç­”ç”¨æˆ·é—®é¢˜ã€‚ä»£ç åº”è¯¥ï¼š
1. è¯»å–æŒ‡å®šçš„Excelæ–‡ä»¶å’Œå·¥ä½œè¡¨
2. ä½¿ç”¨åˆ†æä¸­ç¡®å®šçš„æ•°æ®åˆ—å’Œå‡½æ•°
3. ç”Ÿæˆæ¸…æ™°çš„ç»“æœå’Œå¯è§†åŒ–å›¾è¡¨
4. åŒ…å«è¯¦ç»†çš„æ³¨é‡Šè¯´æ˜

è¿”å›JSONæ ¼å¼ï¼š
{{
    "code": "ç”Ÿæˆçš„Pythonä»£ç ",
    "used_columns": ["ä½¿ç”¨çš„åˆ—ååˆ—è¡¨"],
    "analysis_type": "åˆ†æç±»å‹",
    "expected_output": "é¢„æœŸè¾“å‡ºæè¿°"
}}
"""
        
        return prompt

    async def generate_code_with_retry(
        self,
        question: str,
        file_info: FileSearchResult,
        max_retries: int = 3,
        error_message: str = None
    ) -> CodeGenerationResult:
        """
        å¸¦é‡è¯•æœºåˆ¶çš„ä»£ç ç”Ÿæˆ
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            file_info: é€‰ä¸­çš„æ–‡ä»¶ä¿¡æ¯
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
            error_message: æ‰§è¡Œé”™è¯¯ä¿¡æ¯ï¼ˆç”¨äºé‡æ–°ç”Ÿæˆä»£ç ï¼‰
            
        Returns:
            ä»£ç ç”Ÿæˆç»“æœ
        """
        last_error = error_message
        
        for attempt in range(max_retries):
            try:
                if attempt == 0 and not error_message:
                    # ç¬¬ä¸€æ¬¡å°è¯•ï¼Œä½¿ç”¨åŸå§‹é—®é¢˜
                    prompt = self._build_prompt(question, file_info)
                else:
                    # åç»­å°è¯•ï¼ŒåŒ…å«é”™è¯¯ä¿¡æ¯
                    prompt = self._build_prompt_with_error(question, file_info, last_error, attempt)
                
                messages = [
                    {"role": "system", "content": self._get_system_prompt()},
                    {"role": "user", "content": prompt}
                ]
                
                # è°ƒç”¨GPT-4ç”Ÿæˆä»£ç 
                response = await openai_client.chat_completion(
                    messages,
                    model="gpt-4",
                    temperature=0.2,
                    max_tokens=2000
                )
                
                # è§£æå“åº”
                try:
                    result_json = openai_client.extract_json(response)
                    
                    code_result = CodeGenerationResult(
                        code=result_json.get("code", ""),
                        used_columns=result_json.get("used_columns", []),
                        analysis_type=result_json.get("analysis_type", "æ•°æ®åˆ†æ"),
                        expected_output=result_json.get("expected_output", "")
                    )
                    
                    # è®°å½•æˆåŠŸç”Ÿæˆ
                    logger.log_code_generation(
                        file_info.file_id,
                        question,
                        code_result.code,
                        code_result.used_columns,
                        code_result.analysis_type,
                        True,
                        attempt=attempt + 1
                    )
                    
                    return code_result
                    
                except Exception as e:
                    last_error = f"JSONè§£æå¤±è´¥: {e}"
                    logger.log_error(
                        "code_generation_json_parse_failed",
                        file_info.file_id,
                        f"ç¬¬{attempt + 1}æ¬¡å°è¯•JSONè§£æå¤±è´¥: {e}",
                        raw_response=response[:500]
                    )
                    
            except Exception as e:
                last_error = f"ä»£ç ç”Ÿæˆå¤±è´¥: {e}"
                logger.log_error(
                    "code_generation_failed",
                    file_info.file_id,
                    f"ç¬¬{attempt + 1}æ¬¡å°è¯•å¤±è´¥: {e}"
                )
        
        # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥äº†
        logger.log_error(
            "code_generation_max_retries_exceeded",
            file_info.file_id,
            f"è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°{max_retries}ï¼Œæœ€åé”™è¯¯: {last_error}"
        )
        
        return CodeGenerationResult(
            code="",
            used_columns=[],
            analysis_type="error",
            expected_output=f"ä»£ç ç”Ÿæˆå¤±è´¥ï¼Œå·²é‡è¯•{max_retries}æ¬¡ã€‚æœ€åé”™è¯¯: {last_error}"
        )

    def _get_system_prompt(self) -> str:
        """è·å–ç³»ç»Ÿæç¤ºè¯"""
        return """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„Pythonæ•°æ®åˆ†æå¸ˆï¼Œæ“…é•¿ä½¿ç”¨pandasã€numpyã€matplotlibè¿›è¡Œæ•°æ®åˆ†æã€‚

ä½ éœ€è¦æ ¹æ®ç”¨æˆ·çš„é—®é¢˜å’Œæ•°æ®æ–‡ä»¶ä¿¡æ¯ï¼Œç”Ÿæˆå¯æ‰§è¡Œçš„Pythonä»£ç ã€‚

æ ‡å‡†åº“å¯¼å…¥:

Pandas: å¿…é¡»ä½¿ç”¨ import pandas as pdã€‚åŒæ—¶ï¼Œä¸ºäº†å®Œæ•´æ˜¾ç¤ºæ•°æ®ï¼Œåº”è®¾ç½® pd.set_option('display.max_columns', None) å’Œ pd.set_option('display.max_rows', None)ã€‚
ç›®çš„ï¼šç¡®ä¿åœ¨æ‰“å° DataFrame æ—¶ï¼Œæ‰€æœ‰è¡Œå’Œåˆ—éƒ½èƒ½å®Œæ•´æ˜¾ç¤ºï¼Œé¿å…å› è¾“å‡ºå†…å®¹è¢«æˆªæ–­è€Œä¸¢å¤±å…³é”®ä¿¡æ¯ã€‚
Warnings: å¿…é¡»ä½¿ç”¨ import warnings å¹¶é€šè¿‡ warnings.simplefilter(action='ignore', category=Warning) å±è”½ä¸å¿…è¦çš„è­¦å‘Šä¿¡æ¯ã€‚
ç›®çš„ï¼šä¿æŒæ§åˆ¶å°è¾“å‡ºçš„æ•´æ´æ€§ï¼Œè®©ç”¨æˆ·èƒ½ä¸“æ³¨äºä»£ç æ‰§è¡Œçš„æ ¸å¿ƒç»“æœï¼Œè€Œä¸æ˜¯è¢«æ¬¡è¦çš„è­¦å‘Šä¿¡æ¯å¹²æ‰°ã€‚
ç¼–ç é£æ ¼:

å‘½åè§„èŒƒ: å˜é‡å’Œå‡½æ•°å‘½ååº”é¿å…ä½¿ç”¨ä¸­æ–‡æˆ–ç‰¹æ®Šç¬¦å·ï¼ˆå¦‚ #ï¼‰ï¼Œä»¥é˜²èŒƒè¯­æ³•é”™è¯¯ã€‚
ç›®çš„ï¼šä¿è¯ä»£ç çš„å…¼å®¹æ€§å’Œå¯ç§»æ¤æ€§ï¼Œé¿å…å› ç¼–ç é—®é¢˜æˆ–ç‰¹æ®Šå­—ç¬¦ä¸è¯­æ³•å†²çªè€Œå¯¼è‡´çš„æ½œåœ¨é”™è¯¯ã€‚
ä¿æŒåˆ—å: åœ¨å¤„ç†æ•°æ®æ—¶ï¼Œå¿…é¡»ä¿æŒåŸå§‹åˆ—åä¸­çš„ç‰¹æ®Šå­—ç¬¦ï¼ˆå¦‚ä¸‹åˆ’çº¿ã€å¤šç©ºæ ¼ï¼‰ä¸å˜ã€‚
ç›®çš„ï¼šç»´æŒæ•°æ®çš„åŸå§‹ç»“æ„å’Œä¸Šä¸‹æ–‡ï¼Œç¡®ä¿åç»­æ“ä½œæˆ–ç”¨æˆ·åœ¨æ ¸å¯¹æ•°æ®æ—¶ï¼Œåˆ—åä¸æºæ–‡ä»¶å®Œå…¨ä¸€è‡´ã€‚
ç¨³å¥æ€§:

å¼‚å¸¸å¤„ç†: ç”Ÿæˆçš„ä»£ç å¿…é¡»åŒ…å« try...except ç­‰å¼‚å¸¸å¤„ç†æœºåˆ¶ï¼Œç¡®ä¿ç¨‹åºçš„ç¨³å®šæ€§ã€‚
ç›®çš„ï¼šé˜²æ­¢ç¨‹åºå› æ„å¤–é”™è¯¯ï¼ˆå¦‚æ–‡ä»¶æ ¼å¼é—®é¢˜ã€æ•°æ®ç±»å‹ä¸åŒ¹é…ï¼‰è€Œä¸­æ–­æ‰§è¡Œï¼Œæé«˜ä»£ç çš„å®¹é”™èƒ½åŠ›ã€‚
æ•°å€¼è½¬æ¢: åœ¨è¿›è¡Œæ•°å€¼è®¡ç®—ï¼ˆå¦‚æ±‚å’Œã€æ’åºï¼‰å‰ï¼Œä½¿ç”¨ pd.to_numeric(series, errors='coerce') å°†æ•°æ®åˆ—è½¬æ¢ä¸ºæ•°å€¼ç±»å‹ï¼Œå¹¶å¿½ç•¥ä»»ä½•æ— æ³•è½¬æ¢çš„é”™è¯¯ã€‚
ç›®çš„ï¼šç¡®ä¿æ‰€æœ‰è®¡ç®—æ“ä½œéƒ½åœ¨æ­£ç¡®çš„æ•°å€¼ç±»å‹ä¸Šè¿›è¡Œã€‚errors='coerce' ä¼šå°†æ— æ³•è½¬æ¢çš„å€¼è®¾ä¸º NaNï¼ˆéæ•°å­—ï¼‰ï¼Œä»è€Œé¿å…ç¨‹åºå› ä¸ªåˆ«è„æ•°æ®è€ŒæŠ¥é”™ï¼Œä¿è¯äº†æ•°æ®å¤„ç†æµç¨‹çš„é¡ºç•…ã€‚
å¼ƒç”¨æ–¹æ³•: æ³¨æ„ DataFrame.fillna() æ–¹æ³•çš„ method å‚æ•°å·²ä¸æ¨èä½¿ç”¨ï¼Œåº”é‡‡ç”¨å…¶ä»–æ–¹å¼å¡«å……ã€‚
ç›®çš„ï¼šéµå¾ªåº“çš„æœ€ä½³å®è·µï¼Œç¡®ä¿ä»£ç åœ¨æœªæ¥ç‰ˆæœ¬çš„ Pandas ä¸­ä¾ç„¶èƒ½å¤Ÿæ­£å¸¸è¿è¡Œï¼Œæé«˜ä»£ç çš„é•¿æœŸå¯ç»´æŠ¤æ€§ã€‚

        ä»£ç è¦æ±‚ï¼š
        1. ä½¿ç”¨CSV_FILE_PATHå˜é‡ä½œä¸ºExcelæ•°æ®æ–‡ä»¶è·¯å¾„ï¼ˆæ³¨æ„ï¼šè¿™æ˜¯Excelæ–‡ä»¶ï¼Œä¸æ˜¯CSVï¼‰
        2. å¦‚éœ€ç”Ÿæˆå›¾è¡¨ï¼Œä¿å­˜åˆ°OUTPUT_IMAGE_PATH
        3. å¿…é¡»å¯¼å…¥pandasã€numpy
        4. å¦‚éœ€å¯è§†åŒ–ï¼Œå¯¼å…¥matplotlibå¹¶è®¾ç½®ï¼š
           - matplotlib.use('Agg')
           - plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
        5. å¤„ç†å¯èƒ½çš„ç©ºå€¼å’Œå¼‚å¸¸
        6. ä½¿ç”¨print()è¾“å‡ºæ¸…æ™°çš„åˆ†æç»“è®º
        7. ä»…ä½¿ç”¨æ•°æ®åˆ†æåº“ï¼Œç¦æ­¢ä½¿ç”¨osã€subprocessã€sysç­‰ç³»ç»Ÿæ¨¡å—
        8. ä¸èƒ½ä½¿ç”¨input()ç­‰äº¤äº’æ“ä½œ
        9. æ•°æ®å·²ç»é€šè¿‡df = pd.read_excel(CSV_FILE_PATH)åŠ è½½ï¼Œç›´æ¥ä½¿ç”¨dfå˜é‡è¿›è¡Œåˆ†æ
        10. ä¸è¦é‡å¤åŠ è½½æ•°æ®ï¼Œç›´æ¥ä½¿ç”¨å·²æœ‰çš„dfå˜é‡

è¿”å›JSONæ ¼å¼ï¼š
{
    "code": "å®Œæ•´çš„Pythonä»£ç ",
    "used_columns": ["ä½¿ç”¨çš„åˆ—ååˆ—è¡¨"],
    "analysis_type": "åˆ†æç±»å‹ï¼ˆå¦‚ï¼šè¶‹åŠ¿åˆ†æã€ç»Ÿè®¡æ±‡æ€»ç­‰ï¼‰",
    "expected_output": "é¢„æœŸè¾“å‡ºæè¿°"
}"""
    
    def _build_prompt(self, question: str, file_info: FileSearchResult) -> str:
        """æ„å»ºç”¨æˆ·æç¤ºè¯"""
        # æ„å»ºè¯¦ç»†çš„åˆ—ä¿¡æ¯æ–‡æœ¬
        columns_text = "\n".join([
            f"- {col.name} ({col.type}): {col.description}\n"
            f"  æ ·æœ¬å€¼: {col.sample_values}, å”¯ä¸€å€¼æ•°: {col.unique_count}, ç©ºå€¼æ•°: {col.null_count}"
            for col in file_info.columns[:15]  # é™åˆ¶åˆ—æ•°
        ])
        
        # æ·»åŠ æ•°æ®ç±»å‹ç»Ÿè®¡
        data_types = {}
        for col in file_info.columns:
            dtype = col.type
            if dtype not in data_types:
                data_types[dtype] = []
            data_types[dtype].append(col.name)
        
        data_types_text = "\n".join([
            f"- {dtype}: {', '.join(cols)}"
            for dtype, cols in data_types.items()
        ])
        
        prompt = f"""ç”¨æˆ·é—®é¢˜ï¼š{question}

æ•°æ®æ–‡ä»¶ä¿¡æ¯ï¼š
- æ–‡ä»¶åï¼š{file_info.file_name}
- å·¥ä½œè¡¨ï¼š{file_info.sheet_name or 'é»˜è®¤å·¥ä½œè¡¨'}
- æ‘˜è¦ï¼š{file_info.summary}

åˆ—è¯¦ç»†ä¿¡æ¯ï¼š
{columns_text}

æ•°æ®ç±»å‹åˆ†å¸ƒï¼š
{data_types_text}

è¯·æ ¹æ®ä»¥ä¸Šåˆ—ä¿¡æ¯ç”ŸæˆPythonåˆ†æä»£ç ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚
æ³¨æ„ï¼š
1. ä½¿ç”¨å‡†ç¡®çš„åˆ—åå’Œæ•°æ®ç±»å‹
2. è€ƒè™‘ç©ºå€¼å¤„ç†ï¼ˆnull_count > 0çš„åˆ—ï¼‰
3. åˆ©ç”¨åˆ—æè¿°ç†è§£æ•°æ®çš„ä¸šåŠ¡å«ä¹‰
4. æ•°æ®æ–‡ä»¶è·¯å¾„ä½¿ç”¨å˜é‡CSV_FILE_PATHï¼Œå›¾ç‰‡è¾“å‡ºè·¯å¾„ä½¿ç”¨OUTPUT_IMAGE_PATH
5. åªè¿”å›JSONï¼Œä¸è¦å…¶ä»–è§£é‡Šã€‚"""
        
        return prompt

    def _build_prompt_with_error(
        self,
        question: str,
        file_info: FileSearchResult,
        error_message: str,
        attempt: int
    ) -> str:
        """æ„å»ºåŒ…å«é”™è¯¯ä¿¡æ¯çš„æç¤ºè¯"""
        # æ„å»ºåˆ—ä¿¡æ¯æ–‡æœ¬
        columns_text = "\n".join([
            f"- {col.name} ({col.type}): {col.description}, "
            f"æ ·æœ¬å€¼: {col.sample_values}, å”¯ä¸€å€¼æ•°: {col.unique_count}"
            for col in file_info.columns[:15]  # é™åˆ¶åˆ—æ•°
        ])

        prompt = f"""ç”¨æˆ·é—®é¢˜ï¼š{question}

æ•°æ®æ–‡ä»¶ä¿¡æ¯ï¼š
- æ–‡ä»¶åï¼š{file_info.file_name}
- æ‘˜è¦ï¼š{file_info.summary}
- åˆ—ä¿¡æ¯ï¼š
{columns_text}

ä¹‹å‰çš„ä»£ç æ‰§è¡Œå¤±è´¥ï¼ˆç¬¬{attempt}æ¬¡å°è¯•ï¼‰ï¼š
é”™è¯¯ä¿¡æ¯ï¼š{error_message}

è¯·æ ¹æ®é”™è¯¯ä¿¡æ¯ä¿®æ­£ä»£ç ï¼Œç¡®ä¿ï¼š
1. ä½¿ç”¨æ­£ç¡®çš„åˆ—åï¼ˆæ£€æŸ¥æ‹¼å†™å’Œå¤§å°å†™ï¼‰
2. å¤„ç†æ•°æ®ç±»å‹è½¬æ¢é—®é¢˜
3. å¤„ç†ç©ºå€¼å’Œå¼‚å¸¸æƒ…å†µ
4. ä½¿ç”¨æ­£ç¡®çš„pandasè¯­æ³•
5. ç¡®ä¿æ‰€æœ‰å˜é‡éƒ½å·²å®šä¹‰

è¯·ç”Ÿæˆä¿®æ­£åçš„Pythonåˆ†æä»£ç ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚
è®°ä½ï¼šæ•°æ®æ–‡ä»¶è·¯å¾„ä½¿ç”¨å˜é‡CSV_FILE_PATHï¼Œå›¾ç‰‡è¾“å‡ºè·¯å¾„ä½¿ç”¨OUTPUT_IMAGE_PATHã€‚
åªè¿”å›JSONï¼Œä¸è¦å…¶ä»–è§£é‡Šã€‚"""
        
        return prompt
    
    async def check_and_fix_syntax_errors(self, code: str) -> Tuple[str, bool, Optional[str]]:
        """
        æ£€æŸ¥å¹¶ä¿®å¤ä»£ç è¯­æ³•é”™è¯¯
        
        Args:
            code: è¦æ£€æŸ¥çš„Pythonä»£ç 
            
        Returns:
            (ä¿®å¤åçš„ä»£ç , æ˜¯å¦ä¿®å¤æˆåŠŸ, é”™è¯¯ä¿¡æ¯)
        """
        print("ğŸ” å¼€å§‹è¯­æ³•é”™è¯¯æ£€æŸ¥...")
        
        # ç¬¬ä¸€æ­¥ï¼šä½¿ç”¨ASTæ£€æŸ¥è¯­æ³•
        syntax_error = self._check_syntax_with_ast(code)
        if not syntax_error:
            print("âœ… è¯­æ³•æ£€æŸ¥é€šè¿‡")
            return code, True, None
        
        print(f"âŒ å‘ç°è¯­æ³•é”™è¯¯: {syntax_error}")
        
        # ç¬¬äºŒæ­¥ï¼šä½¿ç”¨GPT-4ä¿®å¤è¯­æ³•é”™è¯¯
        try:
            fixed_code = await self._fix_syntax_with_gpt4(code, syntax_error)
            if fixed_code:
                # éªŒè¯ä¿®å¤åçš„ä»£ç 
                verification_error = self._check_syntax_with_ast(fixed_code)
                if not verification_error:
                    print("âœ… è¯­æ³•é”™è¯¯ä¿®å¤æˆåŠŸ")
                    return fixed_code, True, None
                else:
                    print(f"âŒ ä¿®å¤åä»æœ‰è¯­æ³•é”™è¯¯: {verification_error}")
                    return code, False, f"ä¿®å¤å¤±è´¥: {verification_error}"
            else:
                print("âŒ GPT-4ä¿®å¤å¤±è´¥")
                return code, False, "GPT-4ä¿®å¤å¤±è´¥"
        except Exception as e:
            print(f"âŒ ä¿®å¤è¿‡ç¨‹å¼‚å¸¸: {e}")
            return code, False, f"ä¿®å¤å¼‚å¸¸: {str(e)}"
    
    def _check_syntax_with_ast(self, code: str) -> Optional[str]:
        """
        ä½¿ç”¨ASTæ£€æŸ¥Pythonä»£ç è¯­æ³•
        
        Args:
            code: è¦æ£€æŸ¥çš„ä»£ç 
            
        Returns:
            è¯­æ³•é”™è¯¯ä¿¡æ¯ï¼Œå¦‚æœæ²¡æœ‰é”™è¯¯è¿”å›None
        """
        try:
            ast.parse(code)
            return None
        except SyntaxError as e:
            error_msg = f"è¯­æ³•é”™è¯¯: {e.msg}\nä½ç½®: ç¬¬{e.lineno}è¡Œ, ç¬¬{e.offset}åˆ—"
            if e.text:
                error_msg += f"\né—®é¢˜ä»£ç : {e.text.strip()}"
            return error_msg
        except Exception as e:
            return f"è§£æé”™è¯¯: {str(e)}"
    
    async def _fix_syntax_with_gpt4(self, code: str, syntax_error: str) -> Optional[str]:
        """
        ä½¿ç”¨GPT-4ä¿®å¤è¯­æ³•é”™è¯¯
        
        Args:
            code: æœ‰è¯­æ³•é”™è¯¯çš„ä»£ç 
            syntax_error: è¯­æ³•é”™è¯¯ä¿¡æ¯
            
        Returns:
            ä¿®å¤åçš„ä»£ç ï¼Œå¦‚æœä¿®å¤å¤±è´¥è¿”å›None
        """
        prompt = f"""è¯·ä¿®å¤ä»¥ä¸‹Pythonä»£ç çš„è¯­æ³•é”™è¯¯ã€‚

åŸå§‹ä»£ç :
```python
{code}
```

è¯­æ³•é”™è¯¯ä¿¡æ¯:
{syntax_error}

ä¿®å¤è¦æ±‚:
1. ä¿æŒä»£ç çš„åŸå§‹åŠŸèƒ½å’Œé€»è¾‘
2. åªä¿®å¤è¯­æ³•é”™è¯¯ï¼Œä¸è¦æ”¹å˜ä»£ç ç»“æ„
3. ç¡®ä¿ä¿®å¤åçš„ä»£ç å¯ä»¥æ­£å¸¸æ‰§è¡Œ
4. ä¿æŒæ³¨é‡Šå’Œå˜é‡åä¸å˜

è¯·åªè¿”å›ä¿®å¤åçš„å®Œæ•´Pythonä»£ç ï¼Œä¸è¦å…¶ä»–è§£é‡Šã€‚"""

        messages = [
            {
                "role": "system", 
                "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„Pythonä»£ç ä¿®å¤ä¸“å®¶ï¼Œæ“…é•¿å¿«é€Ÿè¯†åˆ«å’Œä¿®å¤è¯­æ³•é”™è¯¯ã€‚"
            },
            {"role": "user", "content": prompt}
        ]
        
        try:
            response = await openai_client.chat_completion(
                messages,
                model="gpt-4",
                temperature=0.1,
                max_tokens=2000
            )
            
            # æå–ä»£ç 
            fixed_code = self._extract_code_from_response(response)
            return fixed_code
            
        except Exception as e:
            print(f"GPT-4ä¿®å¤è°ƒç”¨å¤±è´¥: {e}")
            return None
    
    def _extract_code_from_response(self, response: str) -> Optional[str]:
        """
        ä»GPT-4å“åº”ä¸­æå–Pythonä»£ç 
        
        Args:
            response: GPT-4çš„å“åº”æ–‡æœ¬
            
        Returns:
            æå–çš„Pythonä»£ç ï¼Œå¦‚æœæå–å¤±è´¥è¿”å›None
        """
        try:
            # å°è¯•æå–ä»£ç å—
            if "```python" in response:
                start = response.find("```python") + 9
                end = response.find("```", start)
                if end != -1:
                    code = response[start:end].strip()
                    return code
            
            # å°è¯•æå–ä»£ç å—ï¼ˆæ²¡æœ‰è¯­è¨€æ ‡è¯†ï¼‰
            if "```" in response:
                start = response.find("```") + 3
                end = response.find("```", start)
                if end != -1:
                    code = response[start:end].strip()
                    # ç®€å•æ£€æŸ¥æ˜¯å¦åƒPythonä»£ç 
                    if any(keyword in code for keyword in ['import', 'def', 'print', 'pd.', 'df.', 'plt.']):
                        return code
            
            # å¦‚æœæ²¡æœ‰ä»£ç å—æ ‡è®°ï¼Œå°è¯•ç›´æ¥ä½¿ç”¨å“åº”
            if any(keyword in response for keyword in ['import', 'def', 'print', 'pd.', 'df.', 'plt.']):
                return response.strip()
            
            return None
            
        except Exception as e:
            print(f"ä»£ç æå–å¤±è´¥: {e}")
            return None


# å…¨å±€å®ä¾‹
code_generator = CodeGenerator()

