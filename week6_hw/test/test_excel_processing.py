#!/usr/bin/env python3
"""
Excelå¤„ç†åŠŸèƒ½æµ‹è¯•
æµ‹è¯•Excelé¢„å¤„ç†ã€å…ƒæ•°æ®ç”Ÿæˆå’ŒElasticsearchç´¢å¼•
"""
import sys
import asyncio
import pandas as pd
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from backend.services.excel_processor import excel_processor
from backend.services.metadata_generator import metadata_generator
from backend.utils.es_client import es_client


async def test_excel_processing():
    """æµ‹è¯•Excelå¤„ç†åŠŸèƒ½"""
    print("ğŸ“Š Excelå¤„ç†åŠŸèƒ½æµ‹è¯•")
    print("=" * 50)
    
    # 1. æµ‹è¯•æ–‡ä»¶åˆ—è¡¨
    test_files = [
        "cola.xlsx",
        "å¤æ‚è¡¨å¤´.xlsx", 
        "å‘ç”µæ—¥å¿—.xlsx"
    ]
    
    original_dir = PROJECT_ROOT / "data" / "original"
    processed_dir = PROJECT_ROOT / "data" / "processed"
    processed_dir.mkdir(exist_ok=True)
    
    for i, filename in enumerate(test_files, 1):
        print(f"\n{i}. æµ‹è¯•æ–‡ä»¶: {filename}")
        
        original_path = original_dir / filename
        if not original_path.exists():
            print(f"   âš ï¸  æ–‡ä»¶ä¸å­˜åœ¨: {original_path}")
            continue
        
        try:
            # å¤„ç†Excelæ–‡ä»¶
            processed_filename = f"processed_{Path(filename).stem}.csv"
            processed_path = processed_dir / processed_filename
            
            print("   å¤„ç†Excelæ–‡ä»¶...")
            log = await excel_processor.process_excel(
                str(original_path),
                str(processed_path)
            )
            
            print(f"   âœ… å¤„ç†å®Œæˆ:")
            print(f"     è·³è¿‡è¡Œæ•°: {log['skipped_rows']}")
            print(f"     è¡¨å¤´è¡Œ: {log['header_row']}")
            print(f"     åˆå¹¶å•å…ƒæ ¼: {log['merged_cells_count']}")
            print(f"     æœ€ç»ˆè¡Œæ•°: {log['final_rows']}")
            print(f"     æœ€ç»ˆåˆ—æ•°: {log['final_columns']}")
            
            # éªŒè¯å¤„ç†ç»“æœ
            if processed_path.exists():
                df = pd.read_csv(processed_path)
                print(f"   ğŸ“Š å¤„ç†åæ•°æ®: {len(df)} è¡Œ x {len(df.columns)} åˆ—")
                print(f"   ğŸ“‹ åˆ—å: {list(df.columns)}")
                
                # æ˜¾ç¤ºå‰å‡ è¡Œæ•°æ®
                print("   ğŸ“„ æ•°æ®é¢„è§ˆ:")
                print(df.head(3).to_string())
                
                # ç”Ÿæˆå…ƒæ•°æ®
                print("   ç”Ÿæˆå…ƒæ•°æ®...")
                metadata = await metadata_generator.generate_metadata(
                    filename,
                    str(original_path),
                    str(processed_path)
                )
                
                print(f"   âœ… å…ƒæ•°æ®ç”ŸæˆæˆåŠŸ:")
                print(f"     æ–‡ä»¶ID: {metadata.file_id}")
                print(f"     æ‘˜è¦: {metadata.summary}")
                print(f"     åˆ—æ•°: {len(metadata.columns)}")
                print(f"     å‘é‡ç»´åº¦: {len(metadata.embedding) if metadata.embedding else 0}")
                
                # æ˜¾ç¤ºåˆ—ä¿¡æ¯
                print("   ğŸ“‹ åˆ—ä¿¡æ¯:")
                for col in metadata.columns[:5]:  # åªæ˜¾ç¤ºå‰5åˆ—
                    print(f"     {col.name} ({col.type}): {col.description}")
                
                # ç´¢å¼•åˆ°Elasticsearch
                print("   ç´¢å¼•åˆ°Elasticsearch...")
                doc = metadata.model_dump()
                doc["created_at"] = doc["created_at"].isoformat()
                doc["updated_at"] = doc["updated_at"].isoformat()
                
                await es_client.index_document(metadata.file_id, doc)
                print("   âœ… å·²ç´¢å¼•åˆ°Elasticsearch")
                
            else:
                print("   âŒ å¤„ç†åæ–‡ä»¶æœªç”Ÿæˆ")
                
        except Exception as e:
            print(f"   âŒ å¤„ç†å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    # 2. æµ‹è¯•æ£€ç´¢åŠŸèƒ½
    print(f"\nğŸ” æµ‹è¯•æ–‡ä»¶æ£€ç´¢...")
    try:
        from backend.services.file_retriever import file_retriever
        
        test_queries = [
            "é”€å”®æ•°æ®",
            "å¯ä¹",
            "å‘ç”µ",
            "å¤æ‚è¡¨å¤´"
        ]
        
        for query in test_queries:
            print(f"   æŸ¥è¯¢: '{query}'")
            results = await file_retriever.search_files(query, top_k=3)
            
            if results:
                print(f"   âœ… æ‰¾åˆ° {len(results)} ä¸ªç›¸å…³æ–‡ä»¶:")
                for result in results:
                    print(f"     - {result.file_name} (å¾—åˆ†: {result.score:.2f})")
            else:
                print("   â„¹ï¸  æœªæ‰¾åˆ°ç›¸å…³æ–‡ä»¶")
                
    except Exception as e:
        print(f"   âŒ æ£€ç´¢æµ‹è¯•å¤±è´¥: {e}")
    
    print("\nğŸ‰ Excelå¤„ç†åŠŸèƒ½æµ‹è¯•å®Œæˆï¼")
    print("=" * 50)


if __name__ == "__main__":
    asyncio.run(test_excel_processing())
